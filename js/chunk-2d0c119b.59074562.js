(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-2d0c119b"],{4537:function(t){t.exports=JSON.parse('{"created_at":"2020-10-17T12:00:02+08:00","excerpt":"KL散度/相对熵：$KL(p||q) = - \\\\int p(x) \\\\ln \\\\left\\\\{ \\\\frac{q(x)}{p(x)} \\\\right\\\\}$，其中p(x)是X的概率密度函数（未知），q(x)是对于X的近似概率密度函数","html":"<h2 id=\\"_1\\">信息论</h2>\\n<p>KL散度/相对熵：<script type=\\"math/tex\\">KL(p||q) = - \\\\int p(x) \\\\ln \\\\left\\\\{ \\\\frac{q(x)}{p(x)} \\\\right\\\\}<\/script>，其中p(x)是X的概率密度函数（未知），q(x)是对于X的近似概率密度函数</p>\\n<p><strong>定理</strong>  <script type=\\"math/tex\\">KL(p||q)\\\\ge 0<\/script>，且等号成立当且仅当 <script type=\\"math/tex\\">p(x) = q(x)<\/script>\\n证1  由<script type=\\"math/tex\\">\\\\ln a \\\\le a-1<\/script> ，有<script type=\\"math/tex\\">-KL(p||q)\\\\le \\\\int p(x) \\\\left( \\\\frac{q(x)}{p(x)} - 1 \\\\right) = 0<\/script>\\n证2  由Jessen不等式可得若f为凸函数，则<script type=\\"math/tex\\">E(f(Y)) \\\\ge f(E[Y])<\/script>，令<script type=\\"math/tex\\">Y=\\\\frac{q(x)}{p(x)}<\/script>，又<script type=\\"math/tex\\">-ln(x)<\/script>是凸函数，故<script type=\\"math/tex\\">KL(p||q) \\\\ge 0<\/script>\\n</p>\\n<p>KL散度的实际意义？TODO</p>\\n<h2 id=\\"ema\\">EMA</h2>\\n<p>指数移动平均（Exponential Moving Average，EMA）是利用历史观测值来预测下一时刻的值的方法，即 <script type=\\"math/tex\\">\\\\hat x_{t+1} = \\\\frac{ \\\\sum_{i = 0}^{t} \\\\beta^i x_{t-i} }{\\\\sum_{i = 0}^{t} \\\\beta^i}, \\\\beta \\\\in (0, 1)<\/script>。显然t+1时刻的预测值<script type=\\"math/tex\\">\\\\hat x_{t+1}<\/script>受近期观测值的影响较大。</p>\\n<p>因为当<script type=\\"math/tex\\">t\\\\rightarrow+\\\\infin<\/script>时，<script type=\\"math/tex\\">\\\\sum\\\\limits_{i = 0}^{t} \\\\beta^i = \\\\frac{1}{1-\\\\beta}<\/script>，代入上式有\\n<script type=\\"math/tex; mode=display\\">\\n\\\\begin{aligned}\\n\\\\hat x_{t+1} = (1-\\\\beta) \\\\left(\\\\sum\\\\limits_{i=0}^{+\\\\infin} \\\\beta^i x_{t-i}\\\\right) \\\\\\\\\\n\\\\end{aligned}\\n<\/script>\\n将下标t+1换成t并在等式两边同时乘上<script type=\\"math/tex\\">\\\\beta<\/script>，可得<script type=\\"math/tex\\">\\\\beta \\\\hat x_{t} = (1-\\\\beta) \\\\left(\\\\sum\\\\limits_{i=1}^{+\\\\infin} \\\\beta^i x_{t-i}\\\\right)<\/script>。前二式做差整理后可得熟悉的EMA公式<script type=\\"math/tex\\">\\\\hat x_{t+1} = \\\\beta \\\\hat x_{t} + (1-\\\\beta) x_t<\/script>\\n</p>\\n<h2 id=\\"svm\\">SVM</h2>\\n<h2 id=\\"em\\">EM</h2>\\n<p>TODO</p>","tags":[{"name":"notes","url":"/tags/notes"},{"name":"machine-learning","url":"/tags/machine-learning"}],"title":"模式识别笔记","updated_at":"2020-10-17T12:00:02+08:00","url":"/docs/course/prml"}')}}]);
//# sourceMappingURL=chunk-2d0c119b.59074562.js.map