(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-2d21eb37"],{d74b:function(e){e.exports=JSON.parse('{"created_at":"2022-01-26T22:47:05+08:00","excerpt":"- Distributed System（分布式系统）","html":"<h2 id=\\"overview\\">Overview</h2>\\n<h3 id=\\"_1\\">操作系统的阶段</h3>\\n<ul>\\n<li>Open Shop（开放车间）</li>\\n<li>Batch Processing（批处理）：先进先出（FIFO）的工作方式</li>\\n<li>FIFO对于系统吞吐率的影响：不利于短作业（就平均等待时间而言），还不利于资源利用（不可分割的程序出错代价高）</li>\\n<li>Multiprogramming（多道程序设计）：受益于技术进步（内存增大、可随机访问的二级存储器、中断硬件）</li>\\n<li>Timesharing（分时）</li>\\n<li>Concurrent Programming（并发程序设计）</li>\\n<li>Personal Computing（PC）</li>\\n<li>Distributed System（分布式系统）</li>\\n</ul>\\n<h2 id=\\"memory-management\\">Memory Management</h2>\\n<h2 id=\\"concurrency\\">Concurrency</h2>\\n<ol>\\n<li>Explain memory hierarchy and cost-performance trade-offs.</li>\\n<li>Summarize the principles of virtual memory as applied to caching and paging.</li>\\n<li>Evaluate the trade-offs in term s of memory size (main memory, cache memory, auxiliary memory) and \\u2028processor speed.</li>\\n<li>Defend the different ways of allocating memory to tasks, citing the relative merits of each.</li>\\n<li>Describe the reason for and use of cache memory (performance and proximity, different dimension of how caches complicate isolation and VM abstraction).</li>\\n<li>Discuss the concept of thrashing, both in terms of the reasons it occurs and the techniques used to recognize and manage the problem. </li>\\n</ol>\\n<h3 id=\\"_2\\">死锁的充要条件</h3>\\n<ul>\\n<li>互斥</li>\\n<li>持有并等待</li>\\n<li>循环等待</li>\\n<li>不可剥夺</li>\\n</ul>\\n<h3 id=\\"deadlock-prevention\\">Deadlock Prevention</h3>\\n<p>破除四个条件中的一个即可，破除互斥（不可行，会产生竞态条件）、破除持有并等待（非持有或者不等待，即不申请或一次性申请）、破除循环等待（单调申请策略、进退策略）、破除不可剥夺</p>\\n<h3 id=\\"deadlock-avoidance\\">Deadlock Avoidance</h3>\\n<p>系统安全，系统安全一定没有死锁，系统不安全可能有死锁，当前系统安全并不意味着之后也安全。</p>\\n<p>在每次分配资源时候，跑银行家算法（<a href=\\"https://en.wikipedia.org/wiki/Banker\'s_algorithm\\">The Banker’s Algorithm</a>）：模拟该次资源分配，并检测系统是否安全，复杂度为<script type=\\"math/tex\\">O(mn^2)<\/script>\\n</p>\\n<ul>\\n<li><code>Available[m]</code>：资源向量，元素为特定资源的总实例数；</li>\\n<li><code>Max[n][m]</code>：进程对资源的需求矩阵，元素<code>Max[i][j]＝k</code>表明进程<code>Pi</code>对资源<code>Rj</code>的总需求实例数为<code>k</code></li>\\n<li><code>Allocation[n][m]</code>：已分配资源矩阵，元素<code>Allocation[i][j]＝k</code>表明进程<code>Pi</code>已获得资源<code>Rj</code>的实例数为<code>k</code></li>\\n<li><code>Need[n][m]</code>：未来资源需求矩阵，元素<code>Need[i][j]＝k</code>表明进程<code>Pi</code>将需要资源<code>Rj</code>的<code>k</code>个实例。显然，<code>Need[i][j]＝ Max[i][j] - Allocation[i][j]</code>。</li>\\n</ul>\\n<table class=\\"codehilitetable\\"><tr><td class=\\"linenos\\"><div class=\\"linenodiv\\"><pre> 1\\n 2\\n 3\\n 4\\n 5\\n 6\\n 7\\n 8\\n 9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25</pre></div></td><td class=\\"code\\"><div class=\\"codehilite\\"><pre><span></span><code>/** The Banker&#39;s Algorithm - Resource-Request Algorithm **/\\n\\n/* Let Request[i][] be the request vector for process Pi.If Request[i][j] = k,then process Pi wants k instances of resource type Rj . When a request for resources is made by process Pi , the following actions are taken */\\n\\n1. If Need[i][] ≤ Request[i][] raise an error condition, since the process has exceeded its maximum claim and exit;\\n2. If Available[] ≤ Request[i][] Pi must wait, since the resources are not available;\\n3. Have the system pretend to have allocated the requested resources to process Pi by modifying the state as follows:\\n   a. Available[] = Available[] – Request[i][] ; \\n   b. Allocation[i][] = Allocation[i][] + Request[i][]; \\n   c. Need[i][] = Need[i][] – Request[i][];\\n   d. If Safety function returns TRUE, the transaction is completed, and process Pi is allocated its resources. Otherwise, Pi must wait for Request[i][] , and the previous resource-allocation state is restored.\\n\\n/** The Banker&#39;s Algorithm - Safety Algorithm **/\\n\\n/* Let Work and Finish be vectors of length m and n, respectively. */ \\n1. Work[] = Available[];\\n2. Finish[] = FALSE;\\n3. Find an index i such that both\\n   a. Finish[i] == FALSE, and\\n   b. Need[i][] ≤ Work;\\n   If no such i exists, go to step 6;\\n3. Work[] = Work[] + Allocation[i][] \\n4. Finish[i] = TRUE;\\n5. Go to step 3;\\n6. Return (Finish[] == TRUE);\\n</code></pre></div>\\n</td></tr></table>\\n\\n<h3 id=\\"deadlock-detection-and-recovery\\">Deadlock Detection and Recovery</h3>\\n<p>不定期跑如下检测算法，类似安全检测算法，复杂度为<script type=\\"math/tex\\">O(m n^2)<\/script>\\n</p>\\n<table class=\\"codehilitetable\\"><tr><td class=\\"linenos\\"><div class=\\"linenodiv\\"><pre> 1\\n 2\\n 3\\n 4\\n 5\\n 6\\n 7\\n 8\\n 9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17</pre></div></td><td class=\\"code\\"><div class=\\"codehilite\\"><pre><span></span><code>/** Deadlock Detection Algorithm **/\\n\\n/* Let Work and Finish be vectors of length m and n, respectively.*/\\n1. Work[] = Available[];\\n2. For i = 0, 1, ..., n–1, \\n      if Allocation[i] != 0 \\n         Finish[i] = FALSE; \\n      else\\n         Finish[i] = TRUE;\\n3. Find an index i such that both\\n      a. Finish[i] == FALSE, and\\n      b. Request[i][] ≤ Work[];\\n   If no such i exists, go to step 7.\\n4. Work[] = Work[] + Allocation[i][]; /* collect resources of Pi */\\n5. Finish[i] = TRUE;\\n6. Go to step 3.\\n7. If Finish[i] == false for some i, 0 ≤ i &lt; n, then the system is in a deadlocked state. More specifically, if Finish[i] == false, then process Pi is deadlocked.\\n</code></pre></div>\\n</td></tr></table>\\n\\n<h2 id=\\"scheduling-and-dispatch\\">Scheduling and Dispatch</h2>\\n<h3 id=\\"_3\\">调度类型</h3>\\n<ul>\\n<li>长程调度：进程一开始是否能被运行，即进程一开始执行的调度</li>\\n<li>中程调度：进程是否要swap，即内存和二级内存（swap分区/磁盘）的调度</li>\\n<li>短程调度：调度就绪队列中哪个进程</li>\\n<li>磁盘调度：安排磁盘访问请求的执行顺序，以减少寻道时间或改善其它性能指标</li>\\n</ul>\\n<h3 id=\\"_4\\">调度性能指标</h3>\\n<ul>\\n<li>CPU利用率</li>\\n<li>吞吐率：单位时间内进程完成数目</li>\\n<li>周转时间：进程从提交到完成的时间（运行时间+等待时间）</li>\\n<li>等待时间：进程处于非运行状态的时间</li>\\n<li>响应时间：从请求开始到开始响应的时间</li>\\n<li>公平性：调度策略应该尽量保持多所有待调度对象的公平处理，在需要优先照顾时也能体现等级差别</li>\\n</ul>\\n<h3 id=\\"_5\\">调度策略</h3>\\n<p>非抢占式调度，也称为协作调度（<a href=\\"https://en.wikipedia.org/wiki/Cooperative_multitasking\\">Nonpreemptive Scheduling</a>）指的是运行进程除非自己主动放弃处理器，其它进程无法获得处理器而投入运行的调度方式。</p>\\n<p>抢占式调度（<a href=\\"https://en.wikipedia.org/wiki/Preemption_(computing)\\">Preemptive Scheduling</a>）指的是当前进程由于非自身主动放弃处理器，而被暂时剥夺执行权力，留待之后再次调度时继续运行的一种调度方式。导致抢占的原因有如基于优先级的调度，时钟中断等。有更好的响应能力、执行调优能力和获得公平性的可能性。</p>\\n<p>一些简单的调度策略如下：</p>\\n<ul>\\n<li>先来先服务（<a href=\\"https://en.wikipedia.org/wiki/First-come,_first-served\\">First-Come-First-Served, FCFS</a>）：优点是公平，缺点是短作业在后的等待时间会比较长，且非抢占式，不适用于分时系统。</li>\\n<li>轮转（<a href=\\"https://en.wikipedia.org/wiki/Round-robin_scheduling\\">Round-Robin, RR</a>）：按照时间片来通过时钟中断抢占CPU。优点是公平、兼顾长短作业，缺点是时间片趋于无穷大时为FCFS，时间片过小则会消耗大量时间在上下文切换上。适用于分时系统。</li>\\n</ul>\\n<h4 id=\\"_6\\">短作业优先</h4>\\n<p>短作业优先（<a href=\\"https://en.wikipedia.org/wiki/Shortest_job_next\\">Shortest-Job-First, SJF</a>或称SPN）：其抢占式版本也称为最小剩余时间优先（<a href=\\"https://en.wikipedia.org/wiki/Shortest_remaining_time\\">Shortest-Remaining-time-First, SRF</a>）策略。易证，SJF将给出最小的平均等待时间。优点是，缺点是，适用于</p>\\n<p>更适合于作业调度（<a href=\\"https://en.wikipedia.org/wiki/Job_scheduler\\">Job Scheduling</a>），属于长程调度范畴。因为用户可以对作业的总运行时间有一个较好的估计。也可用指数移动平均（<a href=\\"https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\\">Exponential Moving Average</a>）方法预测下一次所需时间，令<script type=\\"math/tex\\">t_n<\/script>代表第<script type=\\"math/tex\\">n<\/script>次占用的时间，<script type=\\"math/tex\\">\\\\tau_{n+1}<\/script>为待预测的下一个所需时间，并令<script type=\\"math/tex\\">\\\\tau_{n+1}=\\\\alpha t_n + (1-\\\\alpha)\\\\tau_n, 0\\\\le \\\\alpha \\\\le 1<\/script> 。</p>\\n<h4 id=\\"_7\\">高响应比优先</h4>\\n<p>优先级定义为 <script type=\\"math/tex\\">\\\\text{priority} = \\\\frac{\\\\text{Response Time}}{\\\\text{Expected Service Time}} = \\\\frac{\\\\text{Waiting Time } + \\\\text{ Expected Service Time}}{\\\\text{Expected Service Time}} = \\\\frac{\\\\text{Waiting Time }}{\\\\text{Expected Service Time}}+1<\/script>。若等待时间相同的情况下，则为SJF，若期望服务时间相同，则为FCFS。优点是兼顾了长短作业，缺点是计算需要额外开销，适合批处理系统</p>\\n<h4 id=\\"_8\\">多重反馈队列</h4>\\n<p>将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境</p>\\n<p>TODO</p>\\n<h4 id=\\"_9\\">公平分享</h4>\\n<p>公平分享调度（<a href=\\"https://en.wikipedia.org/wiki/Fair-share_scheduling\\">Fair-Share Scheduling</a>）策略关注进程分享CPU执行机会的公平性。经典的方法有乐透式调度策略（<a href=\\"https://en.wikipedia.org/wiki/Lottery_scheduling\\">Lottery Scheduling</a>）和带有<strong>分组</strong>特征的情况，力图在各个组间保持处理器的均衡分享，并兼顾组内各进程的公平分享。</p>\\n<p>Linux CFS</p>\\n<p>TODO</p>\\n<h2 id=\\"device-management\\">Device Management</h2>\\n<p>TODO</p>\\n<h2 id=\\"file-systems\\">File Systems</h2>\\n<p>TODO</p>\\n<h2 id=\\"virtual-machine\\">Virtual Machine</h2>\\n<p>TODO</p>\\n<h2 id=\\"_10\\">面试题</h2>\\n<p>操作系统的功能：进程管理、内存管理（隔离）、设备管理、API接口</p>\\n<h3 id=\\"_11\\">进程</h3>\\n<p>进程与线程的概念：进程是系统进行资源分配和调度的独立单位，以提高资源利用率和吞吐量；线程是比进程更小的可独立运行的基本单位，可理解为轻量级进程，目的是减少进程切换开销</p>\\n<p>进程和线程的区别：并发性（不同进程间并发、同一进程内的线程并发）、资源（进程是资源分配的单位，而线程资源的很少，但在同一进程下由相同的访问空间）、系统开销（同一进程下的线程由于共享地址空间，便于通信同步）</p>\\n<p>进程通信的几种方式：管道、消息队列、Signal、共享内存</p>\\n<p>进程同步的几种方式</p>\\n<p>用户态、核心态（Kernel Mode）的区别</p>\\n<h3 id=\\"_12\\">死锁</h3>\\n<p>死锁的概念：死锁（<a href=\\"https://en.wikipedia.org/wiki/Deadlock\\">Deadlock</a>）是一种进程间互锁的情况，这组进程中的每一个进程都在以其他进程产生的事件作为推进条件</p>\\n<p>导致死锁的充要条件：互斥、持有并等待、循环等待、不可剥夺</p>\\n<p>处理死锁的方式：预防、避免、检测并恢复、无视（鸵鸟政策）</p>\\n<p>死锁的预防：破除四个条件中的一个即可，具体措施及优缺点分析</p>\\n<p>死锁的避免：银行家算法原理</p>\\n<p>死锁的检测与恢复：检测算法，恢复通常采用鸵鸟政策</p>\\n<h3 id=\\"_13\\">调度</h3>\\n<p>进程调度算法及优缺点分析</p>\\n<p>FCFS、SJF、轮询、高响应比、多重反馈队列</p>\\n<h3 id=\\"vm\\">VM</h3>\\n<p>内存连续分配方式采用的几种算法及各自优劣</p>\\n<p>分页和分段的区别，优缺点比较</p>\\n<p>几种页面置换算法，如何计算所需换页数</p>\\n<p>虚拟内存的定义和实现方式</p>","tags":[{"name":"operating-system","url":"/tags/operating-system"},{"name":"notes","url":"/tags/notes"}],"title":"操作系统笔记","updated_at":"2022-01-26T22:47:05+08:00","url":"/docs/course/os"}')}}]);
//# sourceMappingURL=chunk-2d21eb37.b4c617ec.js.map